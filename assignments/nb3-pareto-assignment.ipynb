{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# A3: Multi-objective Optimization\n",
    "\n",
    "---\n",
    "\n",
    "*Purpose*: Many real engineering problems have multiple objectives. In this case optimization is greatly complicated. In this assignment you'll learn about non-dominance, the Pareto frontier, and how to use optimization to identify a frontier of efficient designs.\n",
    "\n",
    "*Learning Objectives*: By working through this assignment, you will \n",
    "- use pipe-enabled Grama verbs to write *readable* code\n",
    "- use `gr.eval_min()` to solve optimization problems with Grama models\n",
    "- learn the basic concepts of multi-objective optimization: non-dominance and the Pareto frontier\n",
    "- use scalarization techniques and repeated optimization to construct a Pareto frontier\n",
    "\n",
    "*Reading*:\n",
    "- Kochenderfer and Wheeler, Ch 12.1, 12.2, 12.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Assignment Checklist\n",
    "\n",
    "1. [?] Make sure you have answered all questions. These are marked with a **qX.Y**\n",
    "1. [?] Make sure you complete the Project Task at the end of the assignment. These will scaffold your project progress during the semester.\n",
    "1. [?] Make sure your notebook passes all `assert()` statements. You will not get full credit for the assignment if a single `assert()` fails.\n",
    "1. [?] Make sure your notebook runs: `Kernel > Restart kernel and run all cells...`\n",
    "1. [?] Upload your notebook to Canvas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Grading Rubric\n",
    "\n",
    "Every assignment is worth 10 points; it is not possible to receive less than 0 points. For each question (qX.Y) on a given assignment, the following grading rubric will be applied. For every NI that you receive, one point will be subtracted from your assignment total. For reference, to receive an A- in this class, you will need an average of 9 points across your 5 best assignments, meaning you need to have at most one mistake on your final submission for 5 assignments. To achieve this, you should take advantage of both the Draft and Final submission deadlines.\n",
    "\n",
    "| Category     | Needs Improvement (NI)                     | Satisfactory (S)                       |\n",
    "|--------------|--------------------------------------------|----------------------------------------|\n",
    "| Effort       | qX.Y left unattempted                      | qX.Y attempted                         |\n",
    "| Assertions   | Code does not pass an `assert()`           | All `assert()`s pass, or no assertions |\n",
    "| Observations | Any point under *observe* left unattempted | All *observe*s attempted and correct,  |\n",
    "|              | Provided an incorrect observation          | or no *observe*s for that q            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## S1: Sinews and Pipes\n",
    "\n",
    "---\n",
    "\n",
    "First, we'll learn some more useful Grama stuff: Pipelines, the data pronoun, and sinew plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline\n",
    "\n",
    "from grama.models import make_cantilever_beam\n",
    "\n",
    "# Set figure options\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Sinew Plots\n",
    "\n",
    "We'll often have to make sense of high-dimensional functions. One of the most useful things we can do as a \"first check\" of a model is to construct *sinew plots*. Let's look at a very simple function to get some intuition: Here's the function\n",
    "\n",
    "$$f(x, a) = a \\exp(x)$$\n",
    "\n",
    "And here's an implementation in Grama:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "md_simple = (\n",
    "    gr.Model()\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            f=df.a * np.exp(df.x)\n",
    "        ),\n",
    "        var=[\"x\", \"a\"],\n",
    "        out=[\"f\"]\n",
    "    )\n",
    "    >> gr.cp_bounds(\n",
    "        a=(-1, +1),\n",
    "        x=(-1, +1),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "We know this function is going to be *linear* in its argument $a$, and *exponential* in its argument $x$. So if we were to *hold all other variables constant* and vary one input at a time, we could take a look at the effect of just one input. This is what a sinew plot does.\n",
    "\n",
    "*Aside 1*: Some folks call these [ceteris paribus plots](https://ema.drwhy.ai/ceterisParibus.html), where *ceteris paribus* is latin for *all else equal*. I'm not a fan of dead languages, so I just call them sinews.\n",
    "\n",
    "*Aside 2*: Way back in ModSim we had you doing *parameter sweeps*. This is the same thing, but now you can generate parameter sweeps with just a few lines of code!\n",
    "\n",
    "We can get a better sense by visualizing which points the sinew operation will evaluate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    gr.eval_sinews(\n",
    "        md_simple,\n",
    "        df_det=\"swp\",\n",
    "        skip=True,\n",
    "        n_density=20,\n",
    "        n_sweeps=3,\n",
    "        seed=101,\n",
    "    )\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"a\", color=\"factor(sweep_ind)\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Setting `skip=True` tells Grama not to evaluate the functions, but to just give us the points it plans to evaluate. Calling `plot_auto()` on the result uses some metadata to construct an automatic plot that helps visualize the results.\n",
    "\n",
    "NB: Sometimes `plot_auto()` does not play nicely with Jupyter. This is one of those cases, so I've constructed the appropriate plot manually.\n",
    "\n",
    "This plot shows what `eval_sinews()` does: We pick random points in the `a, x` plane (`n_sweeps` of them) and sweep parallel to the axes of `a` and `x`. This gives us a set of points to evaluate. If we get rid of the `skip` keyword, Grama will evaluate the function and show us the response against each input variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.plot_auto(\n",
    "    gr.eval_sinews(\n",
    "        md_simple,\n",
    "        df_det=\"swp\",\n",
    "#         skip=True,\n",
    "        n_density=20,\n",
    "        n_sweeps=3,\n",
    "        seed=101,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Here we can see that indeed, the function is linear in `a` and exponential in `x`. However, we can also see how *other* variables modulate those effects. We can see that, depending on the value of `a`, the function could either grow positively or negatively in `x`. And for the linear growth in `a`, its slope is determined by `x`.\n",
    "\n",
    "For a modest number of variables---say fewer than 5---a sinew plot can help us make sense of our model. With more variables, it's hard to make sense of all the complex interactions between variables in the function. If you have a model with many more variables, you can ask me about *dimension reduction* techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Grama is designed around *analysis pipelines*, in the style of [functional programming](https://en.wikipedia.org/wiki/Functional_programming). In a pipeline one successively applies functions; an advantage of this functional style is that one can easily read individual steps corresponding to each function.\n",
    "\n",
    "To help make functional code readable, Grama functions overload the shift operator `>>` to serve as a *pipe*. The pipe takes its left hand side (LHS), and inserts the LHS as the first argument to the function on its right.\n",
    "\n",
    "**Important concept**: When you see `x >> fun(*args)`, you should think of this as equivalent to `fun(x, *args)`.\n",
    "\n",
    "This pipe operator lets us *transform* code to make it more readable. For instance, the following code is borderline unintelligible:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit, just run and inspect\n",
    "gr.plot_auto(\n",
    "    gr.eval_sinews(\n",
    "        make_cantilever_beam(),\n",
    "        df_det=\"nom\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The previous code is hard to read in part because we need to start from the *inside* of the functions to understand where the computation starts. This is made considerably more readable by introducing *intermediate variables*: The following code does *exactly* the same thing as the code above, but assigns intermediate variables `md_beam` and `df_sweep`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit, just run and inspect\n",
    "md_beam = make_cantilever_beam()\n",
    "df_sweep = gr.eval_sinews(md_beam, df_det=\"nom\")\n",
    "gr.plot_auto(df_sweep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The pipe operator `>>` allows us to remove the intermediate variables, which can be useful when we're carrying out many operations. Let's rewrite the code one last time using pipes. Note that the use of parentheses around the code allows us to use newlines without needing a line continuation character `\\`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit, just run and inspect\n",
    "(\n",
    "    md_beam\n",
    "    >> gr.ev_sinews(df_det=\"nom\")\n",
    "    >> gr.pt_auto()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Note that the *prefix* for the grama functions changed; the pipe-enabled version of the function has a two-letter prefix. The prefixes also denote the inputs and outputs of the function:\n",
    "\n",
    "| Prefix (Short) | Input | Output |\n",
    "|---|---|---\n",
    "| `eval` (`ev`) | Model | DataFrame |\n",
    "| `fit` (`ft`) | DataFrame | Model |\n",
    "| `comp` (`cp`) | Model | Model |\n",
    "| `tran` (`tf`) | DataFrame | DataFrame |\n",
    "| `plot` (`pt`) | DataFrame | (Plot) |\n",
    "\n",
    "You don't need to memorize this table; you can come back and reference it (or better yet, save the relevant [documentation page](https://py-grama.readthedocs.io/en/latest/source/language.html#verbs)). Just know that you can tell a lot about a (Grama) function by looking at its prefix; that alone tells you what type of input it will take, and what type of output it will provide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### q1\\.1 Rewrite this code with pipes\n",
    "\n",
    "Rewrite the following code using the pipe `>>` operator.\n",
    "\n",
    "*Hint*: If you do this correctly, you should get an identical set of histograms as the existing code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Re-write the following code using pipes `>>`\n",
    "###\n",
    "\n",
    "# NOTE: No need to edit; this is the code you'll translate\n",
    "md_beam = make_cantilever_beam()\n",
    "df_mc = gr.eval_sample(md_beam, n=1e3, df_det=\"nom\")\n",
    "gr.plot_auto(df_mc)\n",
    "\n",
    "# TASK: Re-write this code with pipes `>>` to \n",
    "#       eliminate intermediate variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## The data pronoun\n",
    "\n",
    "Grama also provides a function `Intention()`, which allows us to define a *data pronoun*. The setup code above assigns this with `DF = gr.Intention()`, which means we can use `DF` as a data pronoun.\n",
    "\n",
    "### Filtering\n",
    "\n",
    "The use of this shorthand allows us to simplify code. For instance, we can re-write the following filter code:\n",
    "\n",
    "```\n",
    "df_longdataname[df_longdataname[\"x\"] > df_longdataname[\"y\"]]\n",
    "```\n",
    "\n",
    "Using a call to `gr.tf_filter()` using the data pronoun\n",
    "\n",
    "```\n",
    "df_longdataname >> gr.tf_filter(DF[\"x\"] > DF[\"y\"])\n",
    "```\n",
    "\n",
    "### Mutating\n",
    "\n",
    "The use of the data pronoun also allows us to avoid assigning intermediate variables. If we wished to filter then modify data, we would need to do this in pure pandas with an intermediate DataFrame:\n",
    "\n",
    "```\n",
    "df_tmp = df_data[df_data[\"x\"] > x_threshold]\n",
    "df_tmp.y = df_tmp[\"x\"] ** 2\n",
    "```\n",
    "\n",
    "Using `gr.tf_mutate()` we can add / edit a column, and we can use this in a pipeline with a filter to compose the two operations.\n",
    "\n",
    "```\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF[\"x\"] > x_threshold)\n",
    "    >> gr.tf_mutate(y=DF[\"x\"] ** 2)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### q1\\.2 Use the data pronoun to filter\n",
    "\n",
    "Recreate the following pure-pandas filtering operation using a *single* call to `gr.tf_filter()` and the data pronoun `DF`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Recreate the following data manipulation using\n",
    "#       `gr.tf_filter()` and the data pronoun `DF`\n",
    "###\n",
    "\n",
    "# NOTE: No need to edit; this sets up a toy dataset\n",
    "df_foo = gr.df_make(\n",
    "    x=[0, 1, 2],\n",
    "    y=[2, 1, 0],\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; recreate this with a single filter\n",
    "df_tmp = df_foo.copy()\n",
    "df_tmp[\"d\"] = df_tmp[\"x\"]**2 + df_tmp[\"y\"]**2\n",
    "df_tmp[\"b\"] = df_tmp[\"d\"] <= 2\n",
    "df_tmp = df_tmp[df_tmp[\"b\"]]\n",
    "\n",
    "# TASK: Recreate the filtering operation above, but do so with a \n",
    "#       single call of gr.tf_filter() using the data pronoun DF\n",
    "# df_pipe = ???\n",
    "\n",
    "\n",
    "# NOTE: No need to edit; use to check your answer\n",
    "assert(df_pipe.equals(df_tmp[[\"x\", \"y\"]].reset_index(drop=True)))\n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## `eval_min()` and pipeline model adjustments\n",
    "\n",
    "Let's use these ideas to make \"last minute\" adjustments to a model before we use it in an optimization problem.\n",
    "\n",
    "First, let's introduce `gr.eval_min()`: This is a *wrapper* for `scipy.optimize.minimize` that allows us to set an objective and constraints based on model outputs. If we were not using `gr.eval_min()`, we would need to write our own wrapper functions to use a Grama model with `scipy.optimize.minimize`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit; run and inspect\n",
    "md_base = (\n",
    "    gr.Model(\"Example model\")\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            u=df[\"x\"] + df[\"y\"] + 1,\n",
    "            v=df[\"x\"] - df[\"y\"] - 1,\n",
    "        ),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"u\", \"v\"],\n",
    "    )\n",
    "    >> gr.cp_bounds(\n",
    "        x=(-1, +1),\n",
    "        y=(-1, +1),\n",
    "    )\n",
    ")\n",
    "\n",
    "# The following pipeline modifies a model and runs an optimization\n",
    "df_res_tmp = (\n",
    "    md_base\n",
    "    # Add another function to md_base, summarizing its outputs\n",
    "    >> gr.cp_function(\n",
    "        fun=lambda u, v: (0.5 * u + 0.5 * v - 1)**2,\n",
    "        var=[\"u\", \"v\"],\n",
    "        out=[\"obj\"],\n",
    "    )\n",
    "    # Run optimization on this new objective\n",
    "    >> gr.ev_min(out_min=\"obj\")\n",
    ")\n",
    "df_res_tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "We can use this \"just in time\" adjustment to apply the scalarization idea you read about in Kochenderfer and Wheeler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### q1\\.3 Optimize with `gr.eval_min()`\n",
    "\n",
    "Using `md_base` as a starting point, solve the following optimization problem:\n",
    "\n",
    "$$\\min\\, x^2 + y^2$$\n",
    "$$\\text{wrt.}\\, x, y$$\n",
    "$$\\text{s.t.}\\, u(x, y) \\leq 0$$\n",
    "$$\\text{s.t.}\\, v(x, y) \\leq 0$$\n",
    "\n",
    "Solve the optimization problem with `gr.eval_min()`.\n",
    "\n",
    "*Hint*: Remember to use `Shift + Tab` to read the documentation for `gr.eval_min()`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Implement and solve the optimization problem above\n",
    "###\n",
    "\n",
    "df_q1_3 = (\n",
    "    md_base\n",
    "    # TASK: Compose the objective function\n",
    "    # TASK: Optimize with gr.ev_min()\n",
    ")\n",
    "\n",
    "\n",
    "# NOTE: No need to edit, use this to check your solution\n",
    "assert(abs(df_q1_3.x[0] + 0.5) < 1e-6)\n",
    "assert(abs(df_q1_3.y[0] + 0.5) < 1e-6)\n",
    "print(\"Success!\")\n",
    "df_q1_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "One last thing; because vectorized Grama functions take DataFrames and return DataFrames, we can use pipelines *within* a Grama function. This allows us to write more compact code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this demonstrates using pipeline tools\n",
    "# inside a Grama function\n",
    "md_silly = (\n",
    "    gr.Model()\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(f=df.x)\n",
    "        >> gr.tf_mutate(g=DF[\"f\"] + DF[\"y\"]),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"f\", \"g\"]\n",
    "    )\n",
    "    >> gr.cp_bounds(\n",
    "        x=(0, 1),\n",
    "        y=(0, 1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "But the use of pipeline-enabled data manipulation allows us to do *very sophisticated* data operations within a Grama model, which will enable important operations we'll see in NB4. The tricky thing to look out for is to *not* get the variables `df` and `DF` confused; if you run into issues with your code, keep a look out for swapping the two.\n",
    "\n",
    "We'll use these tools for combining model outputs in our efforts to tackle *multi-objective optimization* below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## S2: Tenchi Diagrams and Objectives\n",
    "\n",
    "---\n",
    "\n",
    "The elements of a tenchi diagram are designed to help us understand our model, particularly as it relates to the natural world. Part of the reason we draw the natural world is to keep our attention on what we're actually trying to do (the *usage* part of the tenchi diagram).\n",
    "\n",
    "It's a bit difficult to describe multiple objectives *in the abstract*, because our goals can vary so much between applications. However, there are some *frameworks* that help organize objectives. One such framework is the *triple bottom line*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Triple Bottom Line\n",
    "\n",
    "The [bottom line](https://en.wikipedia.org/wiki/Bottom_line) is more than an idiom; it's a term from accounting that refers either to profit or loss. The implication of the phrase \"bottom line\" is that all that matters is profit (or loss). However, there are recognized limits to considering profit alone (e.g., [climate change](https://en.wikipedia.org/wiki/Climate_change)).\n",
    "\n",
    "Instead, businesses and organizations can consider the [triple bottom line](https://en.wikipedia.org/wiki/Triple_bottom_line#). This is formulated in different ways; the image below lists Economic, Social, and Environmental concerns. You may also hear Profit, People, and Planet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "<img src=\"./images/triple-bottom-line.png\" width=\"600\">\n",
    "\n",
    "**Figure 1.** The triple bottom line concept with example objectives. Author: Clonewayx - Own work CC BY-SA 4.0 [source link](https://en.wikipedia.org/wiki/Triple_bottom_line#/media/File:Triple_Bottom_Line_graphic.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The triple bottom line framework can help help us identify *objectives* (in the optimization sense). The triple bottom line alone doesn't solve our problems (what if a company still chooses to maximize profit alone?), but it can help promote awareness of the tradeoffs being made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### q2\\.1 Identify objectives\n",
    "\n",
    "Study the diagram of the natural world below (Fig. 2). Answer the questions below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "<img src=\"./images/tenchi-daijoubu.png\" width=\"600\">\n",
    "\n",
    "**Figure 2.** Depiction of a fictional automotive company---*Daijoubu Motors*. Some key features in the natural world are depicted, but you need not limit yourself to what's shown in this diagram. Feel free to add some details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "*Observe*:\n",
    "\n",
    "For Daijoubu Motors, identify at least one objective for each of the three \"lines\": Economic, Social, Environmental\n",
    "\n",
    "- Economic\n",
    "  - (Your response here)\n",
    "- Social\n",
    "  - (Your response here)\n",
    "- Environmental\n",
    "  - (Your response here)\n",
    "\n",
    "Pick two objectives that are likely to exhibit *tradeoffs*; that is, you cannot optimize both simultaneously. Ensure to note whether you seek to minimize or maximize each objective. Describe why a tradeoff exists.\n",
    "\n",
    "  - (Objective 1: To minimize or maximize?)\n",
    "  - (Objective 2: To minimize or maximize?)\n",
    "  - (Why they exhibit a tradeoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## S3: Multi-objective Optimization: The Pareto Frontier\n",
    "\n",
    "---\n",
    "\n",
    "To this point we've studied problems that have **just one** objective to optimize. However real engineering problems often have more than one objective. This situation is called *multi-objective optimization*, and it is *inherently* more complicated than single-objective optimization.\n",
    "\n",
    "The following figure illustrates two objective function axes, both of which we wish to maximize. We see a single candidate at the center of the diagram, and the quadrants about that candidate are labeled:\n",
    "\n",
    "<img src=\"./images/obj-multi.png\" width=\"400\">\n",
    "\n",
    "In multi-objective optimization we are *not* guaranteed to be able to order two candidates as inherently better or worse. Instead two candidates can be mutually *non-dominating*---this occurs when one candidate is superior along one or more axes, but the other candidate is superior along different axes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "<img src=\"./images/obj-ex.png\" width=\"400\">\n",
    "\n",
    "The existence of non-dominated candidate pairs means *there is no unique optimum* in the multi-objective setting. Instead, there is a set of non-dominated candidates, as shown in the example above. This set is called the [Pareto frontier](https://en.wikipedia.org/wiki/Pareto_efficiency). \n",
    "\n",
    "You can use the helper function `gr.pareto_min()` to identify Pareto-optimal (non-dominated) points. Note that since this function assumes all provided columns are to be minimized, you can maximize an objective by negating it. The following code demonstrates how to use `gr.pareto_min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit; inspect the code and execute to see the output\n",
    "(\n",
    "    # Generate some data\n",
    "    gr.df_make(\n",
    "        r=gr.marg_mom(\"uniform\", 0, 2*np.pi).r(20),\n",
    "        t=gr.marg_mom(\"uniform\", 0, 1).r(20),\n",
    "    )\n",
    "    >> gr.tf_mutate(\n",
    "        x=DF[\"r\"] * gr.cos(DF[\"t\"]),\n",
    "        y=DF[\"r\"] * gr.sin(DF[\"t\"]),\n",
    "    )\n",
    "    \n",
    "    # Identify the Pareto-optimal points\n",
    "    >> gr.tf_mutate(\n",
    "        pareto=gr.pareto_min(\n",
    "            +DF[\"x\"], # to minimize\n",
    "            -DF[\"y\"], # to maximize\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"y\", color=\"pareto\"))\n",
    "    + gr.geom_point()\n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"X (to minimize)\",\n",
    "        y=\"y (to maximize)\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### q3\\.1 Identify a Pareto Frontier\n",
    "\n",
    "The following is the [Binh and Korn](https://en.wikipedia.org/wiki/Test_functions_for_optimization#Test_functions_for_multi-objective_optimization) optimization problem.\n",
    "\n",
    "$$\\min\\, f_1, f_2$$\n",
    "$$\\text{wrt.}\\, x, y$$\n",
    "$$\\text{s.t.}\\, g_1 \\leq 0$$\n",
    "$$\\text{s.t.}\\, g_2 \\geq 0$$\n",
    "$$\\text{s.t.}\\, 0 \\leq x \\leq 5$$\n",
    "$$\\text{s.t.}\\, 0 \\leq y \\leq 3$$\n",
    "\n",
    "The following code generates data from this problem. Your task is to filter out only those points satisfying the constraints, and to identify the Pareto-optimal points. Answer the questions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Filter the data that satisfy the constraints\n",
    "#       and add a column that identifies Pareto points\n",
    "###\n",
    "\n",
    "# NOTE: No need to edit, this sets up a model to optimize\n",
    "md_BK = (\n",
    "    gr.Model(\"Binh and Korn model\")\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            f1=4 * df.x**2 + 4 * df.y**2\n",
    "        ),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"f1\"],\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            f2=(df.x - 5)**2 + (df.y - 5)**2\n",
    "        ),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"f2\"],\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            g1_leq=(df.x - 5)**2 + df.y**2 - 25\n",
    "        ),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"g1_leq\"],\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            g2_geq=(df.x - 8)**2 - (df.y + 3)**2 - 7.7\n",
    "        ),\n",
    "        var=[\"x\", \"y\"],\n",
    "        out=[\"g2_geq\"],\n",
    "    )\n",
    "    >> gr.cp_bounds(\n",
    "        x=(0, 5),\n",
    "        y=(0, 3),\n",
    "    )\n",
    ")\n",
    "# Generate samples uniformly across the domain\n",
    "df_random = (\n",
    "    md_BK\n",
    "    >> gr.cp_marginals(\n",
    "        x=dict(dist=\"uniform\", loc=0, scale=5),\n",
    "        y=dict(dist=\"uniform\", loc=0, scale=3),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    "    >> gr.ev_sample(n=1e2, df_det=\"nom\", seed=102)\n",
    ")\n",
    "\n",
    "# TASK: Filter the data, compute the Pareto points\n",
    "# df_BK = ???\n",
    "\n",
    "\n",
    "# NOTE: No need to edit; this visualizes your results\n",
    "(\n",
    "    df_BK\n",
    "    >> gr.ggplot(gr.aes(\"f1\", \"f2\"))\n",
    "    + gr.geom_point(gr.aes(color=\"pareto\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "*Observe*:\n",
    "\n",
    "- What shape---roughly---does the Pareto frontier have?\n",
    "  - (Your response here)\n",
    "- Here we approximated the Pareto frontier using *random sampling*. Try increasing the `n` in `gr.ev_monte_carlo()` above; what happens when you increase `n`?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### q3\\.2 Scalarization\n",
    "\n",
    "Use the weight method (Kochenderfer and Wheeler, Ch 12.3) to scalarize the objective $f_1, f_2$ and find a candidate near the \"middle\" of the Pareto frontier. Use `gr.ev_min()` to solve the optimization. Answer the question below.\n",
    "\n",
    "*Hint*: Remember that you can use end a cell with the line `md_BK` to inspect the model to determine the names of its outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Scalarize the objectives f1, f2 with the weight method,\n",
    "#       solve the optimization problem to identify a point on the\n",
    "#       Pareto frontier\n",
    "###\n",
    "\n",
    "# df_BK_opt = ???\n",
    "\n",
    "\n",
    "# NOTE: No need to edit; this visualizes your results\n",
    "(\n",
    "    df_BK\n",
    "    >> gr.ggplot(gr.aes(\"f1\", \"f2\"))\n",
    "    + gr.geom_point(gr.aes(color=\"pareto\"))\n",
    "    + gr.geom_point(data=df_BK_opt, size=4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "*Observe*:\n",
    "\n",
    "- Your identified point (in red) should lie near the \"middle\" of the Pareto frontier. What weights $w_{f_1}, w_{f_2}$ did you choose to find this point?\n",
    "  - (Your response here)\n",
    "- What relationship does the vector $(w_{f_1}, w_{f_2})$ have with the Pareto frontier?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## S4: Case Study: Design of a Cantilever Beam\n",
    "\n",
    "---\n",
    "\n",
    "A [cantilever beam](https://en.wikipedia.org/wiki/Cantilever) is a fundamental structural element. Many engineering systems are cantilevers: airplane wings, draw bridges, microelectronic systems, and so on. When designing structural elements, we often have a fundamental tradeoff to consider: a heavier structure will tend to be safer but more expensive. \n",
    "\n",
    "In this case study we'll consider the sizing of a cantilever beam of predetermined length $l$ in terms of its width $w$ and thickness $t$. This beam is subject to predetermined horizontal and vertical tip load. We seek to minimize its volume $V$, but we also want to minimize its tip displacement $D$. The beam must be structurally sound, so we impose a constraint based on the maximum bending stress $\\sigma_y \\geq \\sigma_{\\text{max bend}}$.\n",
    "\n",
    "The following states our optimization problem in standard form:\n",
    "\n",
    "$$\\min\\, V, D$$\n",
    "$$\\text{wrt.}\\, w, t$$\n",
    "$$\\text{s.t.}\\, 4 \\leq w \\leq 30$$\n",
    "$$\\text{s.t.}\\, 4 \\leq t \\leq 30$$\n",
    "$$\\text{s.t.}\\, \\sigma_y - \\sigma_{\\text{applied}} \\geq 0$$\n",
    "\n",
    "Your first task will be to assemble a Grama model using the following functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: *Assume* values for these variable quantities\n",
    "#       we'll learn how to model this with uncertainty later!\n",
    "E_NOM = 1.45e6 # Modulus of elasticity (psi)\n",
    "H_NOM = 500    # Horizontal tip force (lbs)\n",
    "V_NOM = 1000   # Vertical tip force (lbs)\n",
    "Y_NOM = 2000   # Ultimate stress (psi)\n",
    "l_NOM = 200    # beam length (in)\n",
    "var_cantilever = [\"w\", \"t\"]\n",
    "\n",
    "# NOTE: No need to edit, this sets up the cantilever beam problem\n",
    "def fun_volume(df):\n",
    "    return gr.df_make(vol=df.w * df.t * l_NOM)\n",
    "out_volume = [\"vol\"]\n",
    "\n",
    "def fun_stress_diff(df):\n",
    "    return gr.df_make(\n",
    "        stress_diff=Y_NOM \n",
    "        - 6 * l_NOM * V_NOM / df.w / df.t**2 \n",
    "        - 6 * l_NOM * H_NOM / df.w**2 / df.t\n",
    "    )\n",
    "out_stress_diff = [\"stress_diff\"]\n",
    "\n",
    "def fun_disp(df):\n",
    "    return gr.df_make(\n",
    "        disp=np.float64(4) * l_NOM**3 / E_NOM / df.w / df.t * np.sqrt(\n",
    "        V_NOM**2 / df.t**4 + H_NOM**2 / df.w**4\n",
    "        )\n",
    "    )\n",
    "out_disp = [\"disp\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### q4\\.1 Assemble and inspect the model\n",
    "\n",
    "Assemble a Grama model with the quantities above. Study the sinew plot below and answer the questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Assemble the Grama model for the cantilever beam\n",
    "###\n",
    "\n",
    "md_cantilever = (\n",
    "## TASK: Implement this model\n",
    "## NOTE: Make sure to use gr.cp_vec_function()\n",
    "\n",
    "# NOTE: Use these bounds in your optimization\n",
    "    >> gr.cp_bounds(\n",
    "        w=(4, 30),\n",
    "        t=(4, 30),\n",
    "    )\n",
    ")\n",
    "\n",
    "# NOTE: This will print out a summary of your model\n",
    "md_cantilever.printpretty()\n",
    "\n",
    "# NOTE: This will produce the sinew plot\n",
    "(\n",
    "    md_cantilever\n",
    "    >> gr.ev_sinews(df_det=\"swp\", n_sweeps=10, n_density=20, seed=101)\n",
    "    >> gr.pt_auto()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "*Note*: Remember that each panel above shows a single output against a single input variable, with all other variables held *constant*.\n",
    "\n",
    "*Observe*:\n",
    "\n",
    "- Which variables have a *positive* impact on the following output? Which have a *negative* impact? (Note that I mean *positive* in sign of effect, not in terms of good.)\n",
    "  - `disp`: Positive impact: \n",
    "  - `disp`: Negative impact: \n",
    "  - `vol`: Positive impact: \n",
    "  - `vol`: Negative impact: \n",
    "  - `stress`: Positive impact: \n",
    "  - `stress`: Negative impact: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### q4\\.2 Scalarize the objectives\n",
    "\n",
    "Complete the code below to scalarize the two objectives with the weight method. Use the weights provided in `w_vol, w_disp`.\n",
    "\n",
    "*Note*: Even when you get this right, the code will take a few moments to finish executing, because it runs the optimization 10 times.\n",
    "\n",
    "*Hint*: The following task will have you visualize and interpret these results. You may find that your results do not make sense, in which case, you might need to come back and edit this code to regenerate `df_all`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Add another function to the model to scalarize\n",
    "#       the objectives `vol` and `disp`; use the\n",
    "#       weights w_vol and w_disp\n",
    "###\n",
    "\n",
    "# NOTE: No need to edit the scaffold code; just add at the TASK below\n",
    "\n",
    "# Set the weights for scalarization\n",
    "w_vol = 1e-4\n",
    "w_disp_all = np.logspace(-1, +1, 10)\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "# Iterate over all displacement weights\n",
    "for w_disp in w_disp_all:\n",
    "    md_tmp = (\n",
    "        md_cantilever\n",
    "# TASK: Add another function to the model to scalarize\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # NOTE: The following code minimizes your scalarized\n",
    "    #       objective\n",
    "    df_res = (\n",
    "        md_tmp\n",
    "        >> gr.ev_min(\n",
    "            out_min=\"obj\",\n",
    "            out_geq=[\"stress_diff\"],\n",
    "        )\n",
    "        >> gr.tf_mutate(\n",
    "            pareto=gr.pareto_min(DF.disp, DF.vol),\n",
    "            w_disp=w_disp,\n",
    "        )\n",
    "    )\n",
    "    # Store the results\n",
    "    df_all = pd.concat((df_all, df_res), axis=0)\n",
    "# Reset the dataframe index\n",
    "df_all.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### q4\\.3 Visualize and interpret\n",
    "\n",
    "Visualize the data `df_all` from above with the variables Tip Displacement and Volume. Answer the questions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Visualize your Pareto frontier results; analyze the results\n",
    "###\n",
    "\n",
    "# NOTE: No need to edit; this will generate a random sample of feasible designs\n",
    "df_beam_feasible = (\n",
    "    gr.df_make(\n",
    "        w=gr.marg_mom(\"uniform\", lo=4, up=30).r(100),\n",
    "        t=gr.marg_mom(\"uniform\", lo=4, up=30).r(100),\n",
    "    )\n",
    "    >> gr.tf_md(md=md_cantilever)\n",
    "    >> gr.tf_filter(DF[\"stress_diff\"] >= 0)\n",
    ")\n",
    "\n",
    "# NOTE: Add your results to the following figure\n",
    "(\n",
    "    gr.ggplot(gr.aes(\"vol\", \"disp\"))\n",
    "    # Note: This will show a sample of random designs that satisfy the constraints; \n",
    "    # they are not guaranteed to be optimal. You can pattern match on this code\n",
    "    # to add your own data to the plot\n",
    "    + gr.geom_point(\n",
    "        data=df_beam_feasible,\n",
    "        color=\"grey\",\n",
    "    )\n",
    "    # TODO: Visualize the data in df_all as red points\n",
    "\n",
    "    + gr.labs(\n",
    "        x=\"Volume (in^3)\",\n",
    "        y=\"Tip Displacement (in)\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "*Observe*:\n",
    "\n",
    "- Qualitatively describe the difference between the points you added to the plot (`df_all`), and the feasible designs that we generated for you (`df_beam_feasible`).\n",
    "  - (Your response here)\n",
    "- Qualitatively describe the tradeoff: Both Tip Displacement (D) and Volume (V) are to be minimized, but what shape does the frontier have?\n",
    "  - (Your response here)\n",
    "- At which end of the Pareto frontier do points tend to concentrate? What about the optimization problem can explain this phenomenon?\n",
    "  - (Your response here)\n",
    "- Suppose a customer currently uses a beam sizing at the red `X` pictured above. Based on your Pareto frontier results, what options for improvement would you provide to the customer?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "---\n",
    "\n",
    "### __Project Task__\n",
    "\n",
    "Look back on your project idea from the previous assignment. As we saw in this assignment, many problems have multiple objectives. This project task will help you connect these ideas to your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### q4\\.4 Model\n",
    "\n",
    "*Task*: Refine your tenchi diagram. From nb2, it must already include the following:\n",
    "- A visual depiction of the natural world. Note: This cannot just be words in circles, you must use images (clipart or stick figures are fine).\n",
    "  - Include a system boundary\n",
    "  - Ensure that there are things inside and outside the system boundary\n",
    "  - Usage\n",
    "  - Modeling question\n",
    "- A depiction of the model\n",
    "\n",
    "**New**: For nb2, it must now include:\n",
    "- Three more things visually depicted in your tenchi diagram. These cannot just be words, you must use images (clipart or stick figures are fine).\n",
    "  - Make sure as you're adding things that *they still match your model*. If something is depicted inside your system boundary, but it's not represented by math in the model, then you've made a mistake!\n",
    "- Any (possibly all) of the things you add could be *stakeholder concerns* (see the Math and People sections below).\n",
    "\n",
    "(Your tenchi diagram here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### q4\\.5 Math\n",
    "\n",
    "*Task*: Provide an answer to each point below. Your tenchi diagram should help with this, particularly depicting the Usage.\n",
    "\n",
    "- *Stakeholder Concerns*: Last assignment you wrote down your stakeholders' concerns; copy those over here for your reference. For each stakeholder concern, try to categorize it according to the Triple Bottom Line framework (Economic, Social, or Environmental).\n",
    "  - (Your response here---Economic, Social, or Environmental)\n",
    "- *Multiple objectives*: Are there multiple objectives among your stakeholders' concerns?\n",
    "  - (Your response here)\n",
    "- *Correlated objectives*: Do you have any reason to believe that any of your objectives are *positively correlated*? \n",
    "  - (Your response here)\n",
    "  - *Note*: If two objectives are strongly positively correlated, then we need not consider both objectives. We can optimize one, and the other will be optimized \"for free\".\n",
    "- *Natural tradeoffs*: Do you have any reason to believe that any of your objectives exhibit *tradeoffs*? Do you have a physical reason to believe this?\n",
    "  - (Your response here)\n",
    "  - *Note*: If two (or more) objectives exhibit a tradeoff, then you'll need to consider all the objectives in your project.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "### q4\\.6 People\n",
    "\n",
    "*Task*: We learned that math cannot capture all of the concerns we might have. List at least one of the stakeholder concerns that you cannot formulate using math. Describe why it's hard to formulate using math.\n",
    "- NB. If you can't find at least one concern that fits this description, you haven't thought about the problem hard enough!\n",
    "- (Chosen concern)\n",
    "- (Why it's hard to formulate using math)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "---\n",
    "\n",
    "- del Rosario *et al.*, \"Assessing the frontier: Active learning, model accuracy, and multi-objective candidate discovery and optimization\" (2020) *J. Chem. Phys.*, [link](https://aip.scitation.org/doi/full/10.1063/5.0006124)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
